{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time, os\n",
    "from mongoengine import *\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "import string\n",
    "import sys\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.decomposition import NMF\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from sklearn.preprocessing import normalize\n",
    "import collections\n",
    "\n",
    "\"\"\"\n",
    "MongoDB Document Setup\n",
    "\"\"\"\n",
    "connect(\"mongodb_sephora_reviews\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def nouns(text):\n",
    "    '''Given a string of text, tokenize the text and pull out only the nouns.'''\n",
    "    is_adj = lambda pos: pos[:2] == 'JJ' \n",
    "    is_verb = lambda pos: pos[:2] == 'RB' \n",
    "    is_other_adj = lambda pos: pos[:2] == 'JJR'\n",
    "    is_other_other_adj = lambda pos: pos[:2] == 'JJS' \n",
    "    is_other_verb = lambda pos: pos[:2] == 'RBR'\n",
    "    tokenized = word_tokenize(text)\n",
    "    all_adj = [word for (word, pos) in pos_tag(tokenized) if is_adj(pos) or is_verb(pos) or is_other_adj(pos)\n",
    "              or is_other_other_adj(pos) or is_other_verb(pos)]\n",
    "    return ' '.join(all_adj)\n",
    "\n",
    "\n",
    "def display_topics(model, feature_names, no_top_words, topic_names=None):\n",
    "    for ix, topic in enumerate(model.components_):\n",
    "        if not topic_names or not topic_names[ix]:\n",
    "            print(\"\\nTopic \", ix)\n",
    "        else:\n",
    "            print(\"\\nTopic: ''\",topic_names[ix],\"''\")\n",
    "        print(\", \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "        \n",
    "def clean_text(txt):\n",
    "    txt = \"\".join([c.lower() for c in txt if c not in string.punctuation])\n",
    "    tokens = re.split('\\W+', txt)\n",
    "    txt = \" \".join([ps.stem(word) for word in tokens if word not in stopwords and ps.stem(word) not in blocker_words])\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient('mongodb://localhost:27017/')\n",
    "\n",
    "db = client.mongodb_sephora_reviews\n",
    "\n",
    "df = pd.DataFrame(list(db.reviews.find({})))\n",
    "\n",
    "stopwords = stopwords.words('english')\n",
    "ps = PorterStemmer()\n",
    "blocker_words = ['skin', 'would', 'cleanser', 'around', 'say', 'month', 'day', 'product', 'time', 'week',\n",
    "                'use', 'ive', 'get', 'first', 'start', 'night', 'year', 'sinc', 'everi', 'balm', 'receiv', 'free',\n",
    "                'size', 'test', 'think', 'still', 'like', 'yet', 'cleanser', 'price', 'everyth', 'influenst', \n",
    "                 'sampl', 'thing', 'stuff', 'littl', 'almost', 'thought', 'long', 'amount', 'one', 'cloth', \n",
    "                'sephora', 'morn', 'afterward', 'im', 'go', 'also', 'stuff', 'second', 'took', 'cloth', \n",
    "                 'cotton', 'way', 'face', 'feel', 'love', 'realli', 'tri', 'smell', 'great', 'make', 'well'\n",
    "                , 'good', 'take', 'definit', 'amaz', 'super', 'best', 'got', 'never', 'buy', 'bit', 'lot', 'job'\n",
    "                'want', 'goe', 'review', 'last', 'enough', 'actual', 'sure', 'though', 'usual', 'back', 'seem', \n",
    "                'far', 'anyth', 'howev', 'bought', 'routin', 'perfect', 'see', 'someth', 'come', 'away', \n",
    "                'give', 'dont', 'much', 'even', 'find', 'rins', 'star', 'small', 'know', '2', 'skincar', 'noth'\n",
    "                'right', 'cant', 'two', 'part', 'done', 'came', 'brush', 'wasnt', 'twice', 'pump', 'squeaki',  \n",
    "                'honestli', 'old', 'top', 'prior', 'write', 'wipe', 'nervou', 'eye', 'eyes', 'green', 'blue',\n",
    "                'hazel', 'brown', 'hair', 'not', 'list', 'listed', 'brunett', 'blond', 'chin', 'real', 'bottl', \n",
    "                 'doesnt', 'open', 'auburn', 'aubur', 'gray', 'grey', 'black', 'red', 'other', 'forward', 'nice'\n",
    "                ,'ok']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_data'] = df['review_text'].apply(lambda x: clean_text(x))\n",
    "df['review_rating_cleaned'] = df['review_rating'].apply(lambda x : x.strip('star\" '))\n",
    "df['review_rating_cleaned'] = df['review_rating_cleaned'].apply(lambda x : x.strip('stars'))\n",
    "df['review_rating_cleaned'] = df['review_rating_cleaned'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos = df[df['review_rating_cleaned'] >=3].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_pos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NMF Model & CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv1 = CountVectorizer(ngram_range=(1,1))\n",
    "list_trained =cv1.fit_transform(df_pos['cleaned_data'])\n",
    "\n",
    "\n",
    "nmf_cleanser_reviews = NMF(5)\n",
    "\n",
    "nmf_cleanser_reviews.fit(list_trained)\n",
    "\n",
    "display_topics(nmf_cleanser_reviews, cv1.get_feature_names(), 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Input Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"New to skincare. Need acne remover that will remove oils and clear pores\"\n",
    "text_cleaned = clean_text(text)\n",
    "\n",
    "\n",
    "user_input = cv1.transform([text_cleaned])\n",
    "user_input_transform = nmf_cleanser_reviews.transform(user_input)\n",
    "\n",
    "\n",
    "sephora_nmf_model = nmf_cleanser_reviews.fit_transform(list_trained)\n",
    "nmf_model_df = pd.DataFrame(sephora_nmf_model).add_prefix('topic_')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Cosine Similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_features = normalize(sephora_nmf_model)\n",
    "df_user_input = pd.DataFrame(user_input_transform)\n",
    "user_matrix = df_user_input.loc[0, :]\n",
    "\n",
    "\n",
    "df_features = pd.DataFrame(norm_features)\n",
    "similarities = df_features.dot(user_matrix)\n",
    "sim_dict = similarities.nlargest(100).to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Additional Columns to NMF Model Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dominant_topic = np.argmax(nmf_model_df.values, axis=1)\n",
    "nmf_model_df['dominant_topic'] = dominant_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_model_df[['product', 'user_skin_type', 'review_text', 'cleaned_data', \n",
    "              'review_rating', 'review_rating_cleaned']] = df_pos[['product', 'user_skin_type', 'review_text', \n",
    "                                      'cleaned_data', 'review_rating', 'review_rating_cleaned']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Product's DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_products = pd.DataFrame(list(db.product.find({})))\n",
    "final_df = nmf_model_df.merge(df_products, how='left', left_on='product', right_on='_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_rating = nmf_model_df.groupby('product')['review_rating_cleaned'].mean().round(2).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_df = df_products.merge(product_rating, how='left', left_on='_id', right_on='product')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation System Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "top_matches_dict = collections.defaultdict(list)\n",
    "for k in sim_dict.keys():\n",
    "    if int(nmf_model_df.iloc[k]['review_rating_cleaned']) > 3:\n",
    "        top_matches_dict[k] = nmf_model_df.iloc[k]['product']\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "top_matches_list = set( val for dic in top_matches_dict for val in top_matches_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "product_display_dict = collections.defaultdict(list)\n",
    "for i, k in enumerate(top_matches_list):\n",
    "    if len(product_display_dict) != 5:\n",
    "        product_display_dict[i].append(product_df[product_df['_id'] == k]['product_url'].item())\n",
    "        product_display_dict[i].append(product_df[product_df['_id'] == k]['brand_name'].item())\n",
    "        product_display_dict[i].append(product_df[product_df['_id'] == k]['product_name'].item())\n",
    "        product_display_dict[i].append(product_df[product_df['_id'] == k]['price'])\n",
    "        product_display_dict[i].append(product_df[product_df['_id'] == k]['product_img_url'].item())\n",
    "        product_display_dict[i].append(product_df[product_df['_id'] == k]['review_rating_cleaned'].item())\n",
    "    else:\n",
    "        break\n",
    "\n",
    "product_display_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in top_matches_dict.keys():\n",
    "    print(nmf_model_df.iloc[i]['review_text']+ \",_____ \")\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "#pickle.dump(nmf_cleanser_reviews, open(\"finalized_nmf_model.pkl\", 'wb'))\n",
    "\n",
    "#pickle.dump(cv1, open(\"countvector.pkl\", 'wb'))\n",
    "\n",
    "#pickle.dump(df_features, open(\"df_nmf_features.pkl\", 'wb'))\n",
    "\n",
    "#pickle.dump(product_df, open(\"product_dataframe.pkl\", 'wb'))\n",
    "\n",
    "#pickle.dump(nmf_model_df, open(\"review_dataframe.pkl\", 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_df = nmf_model_df['dominant_topic'].value_counts().reset_index()\n",
    "topic_df['index'] = topic_df['index'].replace({4: 'Topic: Acne', 3: 'Topic: General Cleansing', 1: 'Topic: Dry Skin', 0: 'Topic: Make-up Removing', \n",
    "                     2: 'Topic: Oily Skin'})\n",
    "\n",
    "topic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "bars = alt.Chart(topic_df).mark_bar().encode(\n",
    "   x='dominant_topic',\n",
    "   y=alt.Y('index', sort='-x')\n",
    "    )\n",
    "text = bars.mark_text(\n",
    "    align='left',\n",
    "    baseline='bottom',\n",
    "    fontSize = 10,\n",
    "    dx=3  # Nudges text to right so it doesn't appear on top of the bar\n",
    ").encode(\n",
    "    text='dominant_topic'\n",
    ")\n",
    "#).properties(height=300)\n",
    "              \n",
    "(bars + text).properties(height=400, width = 650)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

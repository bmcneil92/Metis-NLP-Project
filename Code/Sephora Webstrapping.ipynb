{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import requests\n",
    "import time, os\n",
    "from mongoengine import *\n",
    "import pickle\n",
    "\n",
    "with open('sephora_list.pkl', 'rb') as f:\n",
    "    sephora_prod_list = pickle.load(f)\n",
    "\n",
    "\"\"\"\n",
    "MongoDB Document Setup\n",
    "\"\"\"\n",
    "connect(\"mongodb_sephora_reviews\")\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Selenium setup\n",
    "\"\"\"\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"user-data-dir=selenium\") \n",
    "chromedriver = \"/Applications/chromedriver\" # path to the chromedriver executable\n",
    "os.environ[\"webdriver.chrome.driver\"] = chromedriver\n",
    "driver = webdriver.Chrome(chromedriver)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Product(Document):\n",
    "    \"\"\"\n",
    "    Creates MongoDB document in the Product collection.\n",
    "    \"\"\"\n",
    "    brand_name = StringField()\n",
    "    product_name = StringField(unique=True, required=True)\n",
    "    price = FloatField()\n",
    "    size = StringField()\n",
    "    description = StringField()\n",
    "    skin_type = StringField()\n",
    "    skin_concerns = StringField()\n",
    "    formulation = StringField()\n",
    "    ingredient_highlights = StringField()\n",
    "    product_url = StringField()\n",
    "    product_img_url = StringField()\n",
    "\n",
    "    \n",
    "class Reviews(Document):\n",
    "    \"\"\"\n",
    "    Creates MongoDB documentin the Reviews collection.\n",
    "    Uses Product ID as reference.\n",
    "    \"\"\"\n",
    "    product = ReferenceField(Product)\n",
    "    username = StringField()\n",
    "    user_skin_type = StringField()\n",
    "    review_title = StringField()\n",
    "    review_text = StringField()\n",
    "    review_rating = StringField()\n",
    "    #date_posted = StringField()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def soup_get():\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    return soup\n",
    "\n",
    "\n",
    "def sephora_url_generator(baseurl):\n",
    "    full_url = 'sephora.com'+baseurl\n",
    "    return full_url\n",
    "\n",
    "\n",
    "def check_exists_by_xpath(xpath):\n",
    "    try:\n",
    "        driver.find_element_by_xpath(xpath)\n",
    "    except NoSuchElementException:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def create_product_document():\n",
    "    for a in soup.find_all('li', class_='css-1xhaj19'):\n",
    "        if a.img:\n",
    "            img_url = a.img['src']\n",
    "            break\n",
    "        else:\n",
    "            img_url = None    \n",
    "    \n",
    "    #description if statement\n",
    "    if soup.find(text=\"What it is:\") != None and soup.find(text=\"What it is:\").next != \"\":\n",
    "        try:\n",
    "            descrip = soup.find(text=\"What it is:\").next.strip()\n",
    "        except TypeError:\n",
    "            descrip = None\n",
    "    elif soup.find(text=\"What it is: \") != None:\n",
    "        descrip = soup.find(text=\"What it is: \").next.strip()\n",
    "    elif soup.find(text=\"What it is:  \") != None:\n",
    "        descrip = soup.find(text=\"What it is:  \").next.strip()\n",
    "    else:\n",
    "        descrip = None\n",
    "    \n",
    "    \n",
    "    if soup.find(class_='css-15ro776') != None:\n",
    "        size_ = soup.find(class_='css-15ro776').text.strip(\"Size: \")\n",
    "    else:\n",
    "        size_ = None\n",
    "    \n",
    "    #skin_type if statement    \n",
    "    if soup.find(text=\"Skin Type:\") != None:\n",
    "        if soup.find(text=\"Skin Type:\").next.strip() != None:\n",
    "            skin_type_ = soup.find(text=\"Skin Type:\").next.strip()\n",
    "        else:\n",
    "            skin_type_ = None\n",
    "    elif soup.find(text=\"Skin Type: \") != None:\n",
    "        skin_type_ = soup.find(text=\"Skin Type: \").next.strip()\n",
    "    elif soup.find(text=\"Skin Type:  \") != None:\n",
    "        skin_type_ = soup.find(text=\"Skin Type:  \").next.strip()\n",
    "    else:\n",
    "        skin_type_ = None\n",
    "    \n",
    "    \n",
    "    #skin_concerns if statement\n",
    "    if soup.find(text=\"Skincare Concerns:\") != None:\n",
    "        skin_concerns_ = soup.find(text=\"Skincare Concerns:\").next.strip()\n",
    "    elif soup.find(text=\"Skincare Concerns: \") != None:\n",
    "        skin_concerns_ = soup.find(text=\"Skincare Concerns: \").next.strip()\n",
    "    elif soup.find(text=\"Skincare Concerns:  \") != None:\n",
    "        skin_concerns_ = soup.find(text=\"Skincare Concerns:  \").next.strip()\n",
    "    else:\n",
    "        skin_concerns_ = None\n",
    "        \n",
    "    #formuation if statement\n",
    "    if soup.find(text=\"Formulation:\") != None:\n",
    "        formulation_ = soup.find(text=\"Formulation:\").next.strip()\n",
    "    elif soup.find(text=\"Formulation: \") != None:\n",
    "        formulation_ = soup.find(text=\"Formulation: \").next.strip()\n",
    "    elif soup.find(text=\"Formulation:  \") != None:\n",
    "        formulation_ = soup.find(text=\"Formulation: \").next.strip()\n",
    "    else:\n",
    "        formulation_ = None\n",
    "        \n",
    "    #ingredients\n",
    "    if soup.find(text=\"Ingredient Callouts:\") != None:\n",
    "        highlights = soup.find(text=\"Ingredient Callouts:\").next.strip()\n",
    "    elif soup.find(text=\"Ingredient Callouts: \") != None:\n",
    "        highlights = soup.find(text=\"Ingredient Callouts: \").next.strip()\n",
    "    elif soup.find(text=\"Ingredient Callouts:  \") != None:\n",
    "        highlights = soup.find(text=\"Ingredient Callouts:  \").next.strip()\n",
    "    else:\n",
    "        highlights = None\n",
    "        \n",
    "    #price point\n",
    "    try:\n",
    "        price_ = soup.find('b', class_='css-0').text.strip(\"$\")\n",
    "    except AttributeError:\n",
    "        price_ = soup.find('b', class_='css-5fq4jh').text.strip(\"$\")\n",
    "\n",
    "    product_page = Product(\n",
    "        brand_name = soup.find(class_='css-nc375s').text,\n",
    "        product_name = soup.find(class_='css-1pgnl76').text,\n",
    "        price = price_,\n",
    "        size = size_,\n",
    "        description = descrip,\n",
    "        skin_type = skin_type_,\n",
    "        skin_concerns = skin_concerns_,\n",
    "        formulation = formulation_,\n",
    "        ingredient_highlights = highlights,\n",
    "        product_url = driver.current_url,\n",
    "        product_img_url = img_url\n",
    "    ).save()    \n",
    "    \n",
    "    return product_page\n",
    "\n",
    "\n",
    "def create_reviews_documet(beaut_soup_reviews_html, product_page): #soup.select('div:is(.css-13o7eu2)')\n",
    "\n",
    "    for x in beaut_soup_reviews_html:\n",
    "        \n",
    "        if x.find('span',class_='css-t72irq') == None:\n",
    "            skin_type = None\n",
    "        else:\n",
    "            skin_type = x.find('span',class_='css-t72irq').text\n",
    "\n",
    "        if x.find(class_= 'css-m9drnf') == None:\n",
    "            review_title = None\n",
    "        else:\n",
    "            review_title = x.find(class_= 'css-m9drnf').text\n",
    "            \n",
    "        if x.find('strong') == None:\n",
    "            username_ = None\n",
    "        else:\n",
    "            username_ = x.find('strong').text\n",
    "            \n",
    "        review_page = Reviews(\n",
    "            product = product_page,\n",
    "            username = username_,\n",
    "            user_skin_type = skin_type,\n",
    "            review_title = review_title,\n",
    "            review_text = x.find(class_ =\"css-1x44x6f\").text,\n",
    "            review_rating = str(x.find(class_='css-4qxrld'))[16:25].strip('\"')\n",
    "        ).save()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Webscraping Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in sephora_prod_list:\n",
    "    base_url = 'https://www.sephora.com/'+x\n",
    "    driver.get(base_url)  \n",
    "    driver.execute_script(\"window.scrollTo(0, 300)\")\n",
    "    time.sleep(5)\n",
    "    driver.execute_script(\"window.scrollTo(300, 600)\")\n",
    "    time.sleep(5)\n",
    "    driver.execute_script(\"window.scrollTo(600, 900)\")\n",
    "    time.sleep(5)\n",
    "    driver.execute_script(\"window.scrollTo(900, 1200)\")\n",
    "    time.sleep(5)\n",
    "    driver.execute_script(\"window.scrollTo(1200, 1500)\")\n",
    "    time.sleep(5)\n",
    "    driver.execute_script(\"window.scrollTo(1500, 1650)\")\n",
    "    time.sleep(5)\n",
    "    driver.execute_script(\"window.scrollTo(1650, 1700)\")\n",
    "    time.sleep(5)\n",
    "    driver.execute_script(\"window.scrollTo(1700, 2000)\")\n",
    "    soup = soup_get()\n",
    "    \n",
    "    if soup.select('div:is(.css-13o7eu2)') == None:\n",
    "        continue\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        \"\"\"\n",
    "        Create Mongodb document in the product collection.\n",
    "        \"\"\"\n",
    "        #image url collection\n",
    "        product_page = create_product_document()\n",
    "                \n",
    "        \n",
    "        \"\"\"\n",
    "        Create Mongodb document in the reviews collection.\n",
    "        \"\"\"\n",
    "        create_reviews_documet(soup.select('div:is(.css-13o7eu2)'), product_page)\n",
    "    while driver.find_element_by_class_name('css-2anst8').is_enabled() == True:\n",
    "        driver.execute_script(\"window.scrollTo(2000, 2500)\")\n",
    "        time.sleep(1)\n",
    "        if check_exists_by_xpath(\"//*[@id='ratings-reviews-container']/div[2]/ul/li[9]/button\") == True:\n",
    "            driver.find_element_by_xpath(\"//*[@id='ratings-reviews-container']/div[2]/ul/li[9]/button\").click()\n",
    "        elif check_exists_by_xpath(\"//*[@id='ratings-reviews-container']/div[2]/ul/li[8]/button\") == True:\n",
    "            driver.find_element_by_xpath(\"//*[@id='ratings-reviews-container']/div[2]/ul/li[8]/button\").click()\n",
    "        elif check_exists_by_xpath(\"//*[@id='ratings-reviews-container']/div[2]/ul/li[7]/button\") == True:\n",
    "            driver.find_element_by_xpath(\"//*[@id='ratings-reviews-container']/div[2]/ul/li[7]/button\").click()\n",
    "        elif check_exists_by_xpath(\"//*[@id='ratings-reviews-container']/div[2]/ul/li[6]/button\") == True:\n",
    "            driver.find_element_by_xpath(\"//*[@id='ratings-reviews-container']/div[2]/ul/li[6]/button\").click()\n",
    "        elif check_exists_by_xpath(\"//*[@id='ratings-reviews-container']/div[2]/ul/li[5]/button\") == True:\n",
    "            driver.find_element_by_xpath(\"//*[@id='ratings-reviews-container']/div[2]/ul/li[5]/button\").click()\n",
    "        elif check_exists_by_xpath(\"//*[@id='ratings-reviews-container']/div[2]/ul/li[4]/button\") == True:\n",
    "            driver.find_element_by_xpath(\"//*[@id='ratings-reviews-container']/div[2]/ul/li[4]/button\").click()\n",
    "        elif check_exists_by_xpath(\"//*[@id='ratings-reviews-container']/div[2]/ul/li[3]/button\") == True:\n",
    "            driver.find_element_by_xpath(\"//*[@id='ratings-reviews-container']/div[2]/ul/li[3]/button\").click()\n",
    "        elif check_exists_by_xpath(\"//*[@id='ratings-reviews-container']/div[2]/ul/li[2]/button\") == True:\n",
    "            driver.find_element_by_xpath(\"//*[@id='ratings-reviews-container']/div[2]/ul/li[2]/button\").click()\n",
    "        else:\n",
    "            break \n",
    "        #driver.find_element_by_xpath(\"//*[@id='ratings-reviews-container']/div[2]/ul/li[9]/button\").click()\n",
    "        soup = soup_get()      \n",
    "        create_reviews_documet(soup.select('div:is(.css-13o7eu2)'), product_page) \n",
    "    print(f\"Scrapping Completed for {x}\")\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
